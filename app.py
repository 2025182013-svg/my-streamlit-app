import streamlit as st
import requests
import pandas as pd
import re
from openai import OpenAI
from urllib.parse import urlparse

# =====================
# Page Config
# =====================
st.set_page_config(page_title="RefNote AI", layout="wide")

# =====================
# Sidebar - API Keys
# =====================
st.sidebar.title("ğŸ” API Keys")
openai_api_key = st.sidebar.text_input("OpenAI API Key", type="password")
naver_client_id = st.sidebar.text_input("Naver Client ID", type="password")
naver_client_secret = st.sidebar.text_input("Naver Client Secret", type="password")

if not (openai_api_key and naver_client_id and naver_client_secret):
    st.sidebar.warning("API Keyë¥¼ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

client = OpenAI(api_key=openai_api_key)

# =====================
# Session State
# =====================
if "result" not in st.session_state:
    st.session_state.result = None

# =====================
# Utils
# =====================
def clean_html(text):
    return re.sub("<.*?>", "", text)

# =====================
# GPT: Questions + Keywords (JSON)
# =====================
def generate_questions_and_keywords(topic, task_type):
    prompt = f"""
ì£¼ì œ: {topic}
ê³¼ì œ ìœ í˜•: {task_type}

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´.

{{
  "questions": [
    "ë¦¬ì„œì¹˜ ì§ˆë¬¸ 1",
    "ë¦¬ì„œì¹˜ ì§ˆë¬¸ 2",
    "ë¦¬ì„œì¹˜ ì§ˆë¬¸ 3"
  ],
  "keywords": [
    "í‚¤ì›Œë“œ1",
    "í‚¤ì›Œë“œ2",
    "í‚¤ì›Œë“œ3",
    "í‚¤ì›Œë“œ4",
    "í‚¤ì›Œë“œ5"
  ]
}}
"""
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
        timeout=20
    )
    return eval(res.choices[0].message.content)

# =====================
# GPT: Research Trend
# =====================
def summarize_trends(keywords):
    prompt = f"""
ë‹¤ìŒ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ êµìœ¡Â·ì—°êµ¬ ê´€ì ì˜ ìµœì‹  ì—°êµ¬ ë™í–¥ì„ 200ì ì´ë‚´ë¡œ ìš”ì•½í•´ì¤˜.
í‚¤ì›Œë“œ: {", ".join(keywords)}
"""
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
        timeout=15
    )
    return res.choices[0].message.content

# =====================
# Naver News Search (Filtered)
# =====================
def search_naver_news(keywords):
    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": naver_client_id,
        "X-Naver-Client-Secret": naver_client_secret
    }

    rows = []

    for kw in keywords:
        params = {"query": kw, "display": 10, "sort": "date"}
        res = requests.get(url, headers=headers, params=params, timeout=10)
        if res.status_code != 200:
            continue

        for item in res.json().get("items", []):
            title = clean_html(item["title"])
            desc = clean_html(item["description"])

            # ğŸ” í•µì‹¬ í‚¤ì›Œë“œ 2ê°œ ì´ìƒ í¬í•¨ëœ ê¸°ì‚¬ë§Œ
            match_count = sum(k in title + desc for k in keywords)
            if match_count < 2:
                continue

            rows.append({
                "ì œëª©": title,
                "ìš”ì•½": desc,
                "ì—°ë„": item["pubDate"][:4],
                "ì¶œì²˜": item["originallink"],
                "ê´€ë ¨ë„": match_count
            })

    df = pd.DataFrame(rows)
    if df.empty:
        return df

    return df.sort_values(["ê´€ë ¨ë„", "ì—°ë„"], ascending=[False, False]).head(10)

# =====================
# APA Citation
# =====================
def apa(row):
    domain = urlparse(row["ì¶œì²˜"]).netloc.replace("www.", "")
    return f"{domain}. ({row['ì—°ë„']}). {row['ì œëª©']}. {row['ì¶œì²˜']}"

# =====================
# UI
# =====================
st.title("ğŸ“š RefNote AI")
st.caption("ì¶œì²˜ ê¸°ë°˜ ë¦¬ì„œì¹˜ ì–´ì‹œìŠ¤í„´íŠ¸")

topic = st.text_input("ì–´ë–¤ ì£¼ì œë¡œ ìë£Œë¥¼ ì¤€ë¹„í•˜ë‚˜ìš”?")
task_type = st.selectbox("ê³¼ì œ ìœ í˜•", ["ë°œí‘œ", "ë¦¬í¬íŠ¸", "ê¸°íšì„œ", "ë…¼ë¬¸"])

if st.button("ë¦¬ì„œì¹˜ ì‹œì‘") and topic:
    with st.spinner("ë¦¬ì„œì¹˜ ì§„í–‰ ì¤‘..."):
        parsed = generate_questions_and_keywords(topic, task_type)
        questions = parsed["questions"]
        keywords = parsed["keywords"]

        trend = summarize_trends(keywords)
        df = search_naver_news(keywords)

        st.session_state.result = {
            "questions": questions,
            "keywords": keywords,
            "trend": trend,
            "df": df
        }

# =====================
# Output
# =====================
if st.session_state.result:
    r = st.session_state.result

    st.subheader("ğŸ” ë¦¬ì„œì¹˜ ì§ˆë¬¸ (3ê°œ)")
    for q in r["questions"]:
        st.write("â€¢", q)

    st.subheader("ğŸ”‘ ì‚¬ìš©ëœ ê²€ìƒ‰ í‚¤ì›Œë“œ")
    st.write(", ".join(r["keywords"]))

    st.subheader("ğŸ§  ìµœì‹  ì—°êµ¬ ë™í–¥ ìš”ì•½")
    st.write(r["trend"])

    st.subheader("ğŸ“Š ê·¼ê±° ìë£Œ í…Œì´ë¸”")
    st.dataframe(r["df"][["ì œëª©", "ì—°ë„", "ì¶œì²˜"]], use_container_width=True)

    st.subheader("ğŸ“ ì°¸ê³ ë¬¸í—Œ (APA í˜•ì‹, TOP 10)")
    for i, row in enumerate(r["df"].iterrows(), 1):
        st.write(f"{i}. {apa(row[1])}")
