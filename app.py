import streamlit as st
import requests
import html
from datetime import datetime
from openai import OpenAI

# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(page_title="RefNote AI", layout="wide")
st.title("ğŸ“š RefNote AI")
st.caption("ì¶œì²˜ ê¸°ë°˜ ë¦¬ì„œì¹˜ ì–´ì‹œìŠ¤í„´íŠ¸")

# =========================
# API ì„¤ì •
# =========================
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

NAVER_CLIENT_ID = st.secrets["NAVER_CLIENT_ID"]
NAVER_CLIENT_SECRET = st.secrets["NAVER_CLIENT_SECRET"]

# =========================
# ìœ í‹¸ í•¨ìˆ˜
# =========================
def clean_text(text):
    return html.unescape(text).replace("<b>", "").replace("</b>", "").strip()

def parse_date(date_str):
    try:
        return datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %z")
    except:
        return None

# =========================
# 1. ë¦¬ì„œì¹˜ ì§ˆë¬¸ ìƒì„±
# =========================
def generate_research_questions(topic):
    prompt = f"""
    ë‹¤ìŒ ì—°êµ¬ ì£¼ì œì— ëŒ€í•´ í•™ìˆ ì ìœ¼ë¡œ ì ì ˆí•œ ì—°êµ¬ ì§ˆë¬¸ 3ê°œë¥¼ ìƒì„±í•´ì¤˜.
    ë²ˆí˜¸ ì—†ì´ ë¶ˆë¦¿(-) í˜•íƒœë¡œ ì¶œë ¥.

    ì£¼ì œ: {topic}
    """

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )

    return [
        q.strip("- ").strip()
        for q in res.choices[0].message.content.split("\n")
        if q.strip()
    ]

# =========================
# 2. ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ
# =========================
def extract_keywords(topic):
    prompt = f"""
    ë‹¤ìŒ ì—°êµ¬ ì£¼ì œì—ì„œ ê²€ìƒ‰ìš© í•µì‹¬ í‚¤ì›Œë“œ 5ê°œë¥¼ ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜.
    ì‰¼í‘œ(,)ë¡œë§Œ êµ¬ë¶„í•´ì„œ ì¶œë ¥.

    ì£¼ì œ: {topic}
    """

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )

    return [k.strip() for k in res.choices[0].message.content.split(",")]

# =========================
# 3. ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰
# =========================
def search_naver_news(query):
    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    params = {
        "query": query,
        "display": 30,
        "sort": "date"
    }

    res = requests.get(url, headers=headers, params=params)
    res.raise_for_status()

    results = []
    for item in res.json()["items"]:
        results.append({
            "title": clean_text(item["title"]),
            "description": clean_text(item["description"]),
            "link": item["link"],
            "date": parse_date(item["pubDate"])
        })
    return results

# =========================
# 4. AI ë‰´ìŠ¤ ê´€ë ¨ë„ í‰ê°€
# =========================
def relevance_score(topic, news):
    prompt = f"""
    ë‹¤ìŒ ë‰´ìŠ¤ê°€ ì—°êµ¬ ì£¼ì œì™€ ì–¼ë§ˆë‚˜ ê´€ë ¨ ìˆëŠ”ì§€ 0~3ì ìœ¼ë¡œ í‰ê°€í•´ì¤˜.
    ìˆ«ìë§Œ ì¶œë ¥.

    ì—°êµ¬ ì£¼ì œ: {topic}
    ë‰´ìŠ¤ ì œëª©: {news['title']}
    ë‰´ìŠ¤ ìš”ì•½: {news['description']}
    """

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )

    try:
        return int(res.choices[0].message.content.strip())
    except:
        return 0

# =========================
# 5. APA ì°¸ê³ ë¬¸í—Œ ë³€í™˜
# =========================
def to_apa(news):
    year = news["date"].year if news["date"] else "n.d."
    domain = news["link"].split("/")[2]
    return f"{domain}. ({year}). {news['title']}. {news['link']}"

# =========================
# UI ì…ë ¥
# =========================
topic = st.text_input("ì–´ë–¤ ì£¼ì œë¡œ ìë£Œë¥¼ ì¤€ë¹„í•˜ë‚˜ìš”?")
task_type = st.selectbox("ê³¼ì œ ìœ í˜•", ["ë…¼ë¬¸", "ë°œí‘œ"])

if st.button("ğŸ” ë¦¬ì„œì¹˜ ì‹œì‘") and topic:
    with st.spinner("ë¦¬ì„œì¹˜ ì§„í–‰ ì¤‘..."):

        # ë¦¬ì„œì¹˜ ì§ˆë¬¸
        questions = generate_research_questions(topic)
        st.subheader("ğŸ” ë¦¬ì„œì¹˜ ì§ˆë¬¸ (3ê°œ)")
        for q in questions:
            st.markdown(f"â€¢ {q}")

        # í‚¤ì›Œë“œ
        keywords = extract_keywords(topic)
        st.subheader("ğŸ”‘ ê²€ìƒ‰ í‚¤ì›Œë“œ")
        st.write(", ".join(keywords))

        # ë‰´ìŠ¤ ìˆ˜ì§‘
        all_news = []
        for kw in keywords[:2]:
            all_news.extend(search_naver_news(kw))

        # AI í•„í„°ë§
        filtered = []
        for n in all_news:
            score = relevance_score(topic, n)
            if score >= 2:
                n["score"] = score
                filtered.append(n)

        # ì •ë ¬
        sort_option = st.radio("ì •ë ¬ ê¸°ì¤€", ["ê´€ë ¨ë„ìˆœ", "ìµœì‹ ìˆœ"], horizontal=True)

        if sort_option == "ê´€ë ¨ë„ìˆœ":
            filtered.sort(key=lambda x: (-x["score"], x["date"] or datetime.min))
        else:
            filtered.sort(key=lambda x: x["date"] or datetime.min, reverse=True)

        # ê²°ê³¼ ì¶œë ¥
        st.subheader("ğŸ“Š ê·¼ê±° ìë£Œ (ë‰´ìŠ¤)")
        for n in filtered:
            st.markdown(
                f"""
                **{n['title']}**  
                {n['description']}  
                ğŸ—“ {n['date'].strftime('%Y-%m-%d') if n['date'] else 'ë‚ ì§œ ì—†ìŒ'}  
                ğŸ”— {n['link']}
                """
            )

        # APA ì°¸ê³ ë¬¸í—Œ
        st.subheader("ğŸ“ ì°¸ê³ ë¬¸í—Œ (APA í˜•ì‹, TOP 10)")
        for ref in filtered[:10]:
            st.markdown(f"- {to_apa(ref)}")
