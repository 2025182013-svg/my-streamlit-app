# FULL UPDATED CODE WITH:
# 1) APA7 STRICT FORMAT
# 2) DATE FOLDER HISTORY
# 3) FILENAME = TOPIC BASED
# 4) STRONGER NEWS FILTERING

import streamlit as st
import requests, html, json, os, re
from datetime import datetime
from openai import OpenAI
import pandas as pd

# =====================
# ê¸°ë³¸ ì„¤ì •
# =====================
st.set_page_config(page_title="RefNote AI", layout="wide")
st.title("ğŸ“š RefNote AI")
st.caption("ì—°êµ¬ ë¦¬ì„œì¹˜ ìë™í™” ì‹œìŠ¤í…œ Â· APA7 strict Â· ë‚ ì§œë³„ íˆìŠ¤í† ë¦¬ Â· ì£¼ì œê¸°ë°˜ íŒŒì¼ëª…")

HISTORY_DIR = "history"

# =====================
# ì„¸ì…˜ ìƒíƒœ
# =====================
if "results" not in st.session_state:
    st.session_state.results = None

# =====================
# ì‚¬ì´ë“œë°” API
# =====================
st.sidebar.header("ğŸ”‘ API ì„¤ì •")
openai_key = st.sidebar.text_input("OpenAI API Key", type="password")
naver_id = st.sidebar.text_input("Naver Client ID", type="password")
naver_secret = st.sidebar.text_input("Naver Client Secret", type="password")

if not openai_key:
    st.warning("â¬…ï¸ OpenAI API Key í•„ìˆ˜")
    st.stop()

client = OpenAI(api_key=openai_key)

# =====================
# ìœ í‹¸
# =====================
def clean(t):
    return html.unescape(t).replace("<b>", "").replace("</b>", "").strip()


def parse_date(d):
    try:
        return datetime.strptime(d, "%a, %d %b %Y %H:%M:%S %z")
    except:
        return None


def format_source(domain):
    return domain.replace("www.", "").split(".")[0].capitalize()


def slugify(text):
    text = re.sub(r"[^ê°€-í£a-zA-Z0-9]+", "_", text)
    return text[:50]


# =====================
# APA7 STRICT
# =====================
def apa_news_strict(row):
    author = row.get("ì¶œì²˜", "Unknown")
    date_raw = row.get("ë°œí–‰ì¼", "")
    try:
        dt = datetime.strptime(date_raw, "%Y-%m-%d")
        date_fmt = dt.strftime("%Y, %B %d")
    except:
        date_fmt = "n.d."
    title = row["ì œëª©"]
    source = row["ì¶œì²˜"]
    url = row["ë§í¬"]
    return f"{author}. ({date_fmt}). {title}. {source}. {url}"

# =====================
# AI
# =====================
def gen_questions(topic):
    r = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": f"ë‹¤ìŒ ì£¼ì œì— ëŒ€í•œ ì—°êµ¬ ì§ˆë¬¸ 3ê°œ ìƒì„±:\n{topic}"}],
        temperature=0.3
    )
    return [q.strip("-â€¢ ") for q in r.choices[0].message.content.split("\n") if q.strip()]


def gen_keywords(topic):
    r = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": f"ë‹¤ìŒ ì£¼ì œ í•µì‹¬ í‚¤ì›Œë“œ 5ê°œë¥¼ ì¤‘ìš”ë„ìˆœ ì‰¼í‘œ ì¶œë ¥:\n{topic}"}],
        temperature=0.2
    )
    return [k.strip() for k in r.choices[0].message.content.split(",")]


def gen_trend_summary(keywords):
    r = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": f"í‚¤ì›Œë“œ ê¸°ë°˜ ìµœì‹  ì—°êµ¬ë™í–¥ ìš”ì•½:\n{', '.join(keywords)}"}],
        temperature=0.2
    )
    return r.choices[0].message.content.strip()


def relevance(topic, n):
    r = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": f"ì—°êµ¬ì£¼ì œ:{topic}\nì œëª©:{n['ì œëª©']}\nìš”ì•½:{n['ìš”ì•½']}\nê´€ë ¨ë„ 0~3 ìˆ«ìë§Œ"}],
        temperature=0
    )
    try:
        return int(r.choices[0].message.content.strip())
    except:
        return 0

# =====================
# ë‰´ìŠ¤ (ê°•í™” í•„í„°ë§)
# =====================
def search_news_korea(q):
    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": naver_id,
        "X-Naver-Client-Secret": naver_secret
    }
    params = {"query": q, "display": 40, "sort": "date"}
    r = requests.get(url, headers=headers, params=params).json()

    out = []
    for i in r.get("items", []):
        out.append({
            "ì œëª©": clean(i["title"]),
            "ìš”ì•½": clean(i["description"]),
            "ì¶œì²˜": format_source(i["link"
