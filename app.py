import streamlit as st
import requests
import pandas as pd
import re
from openai import OpenAI
from urllib.parse import urlparse

# =====================
# Config
# =====================
st.set_page_config(page_title="RefNote AI", layout="wide")

# =====================
# Sidebar - API Keys
# =====================
st.sidebar.title("ğŸ” API Keys")
openai_api_key = st.sidebar.text_input("OpenAI API Key", type="password")
naver_client_id = st.sidebar.text_input("Naver Client ID", type="password")
naver_client_secret = st.sidebar.text_input("Naver Client Secret", type="password")

if not (openai_api_key and naver_client_id and naver_client_secret):
    st.sidebar.warning("API Keyë¥¼ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

client = OpenAI(api_key=openai_api_key)

# =====================
# Utils
# =====================
def clean_html(text):
    return re.sub("<.*?>", "", text)

def extract_year(pub_date):
    match = re.search(r"\d{4}", pub_date)
    return match.group() if match else "N/A"

# =====================
# GPT Functions
# =====================
def generate_questions_and_keywords(topic, task_type):
    prompt = f"""
ì£¼ì œ: {topic}
ê³¼ì œ ìœ í˜•: {task_type}

JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•´.

{{
 "questions": [
  "ì§ˆë¬¸1",
  "ì§ˆë¬¸2",
  "ì§ˆë¬¸3"
 ],
 "keywords": ["í‚¤ì›Œë“œ1","í‚¤ì›Œë“œ2","í‚¤ì›Œë“œ3","í‚¤ì›Œë“œ4","í‚¤ì›Œë“œ5"]
}}
"""
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    return eval(res.choices[0].message.content)

def summarize_trends(keywords):
    prompt = f"""
ë‹¤ìŒ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ êµìœ¡Â·ì—°êµ¬ ê´€ì  ìµœì‹  ì—°êµ¬ ë™í–¥ì„ 200ì ì´ë‚´ë¡œ ìš”ì•½.
í‚¤ì›Œë“œ: {", ".join(keywords)}
"""
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    return res.choices[0].message.content

# =====================
# News Search
# =====================
def search_naver_news(keywords):
    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": naver_client_id,
        "X-Naver-Client-Secret": naver_client_secret
    }

    rows = []

    for kw in keywords:
        params = {"query": kw, "display": 10, "sort": "date"}
        res = requests.get(url, headers=headers, params=params)
        if res.status_code != 200:
            continue

        for item in res.json().get("items", []):
            title = clean_html(item["title"])
            desc = clean_html(item["description"])

            # ğŸ”½ ë‰´ìŠ¤ëŠ” í‚¤ì›Œë“œ 1ê°œë§Œ í¬í•¨í•´ë„ OK
            if not any(k in title + desc for k in keywords):
                continue

            rows.append({
                "ì œëª©": title,
                "ìš”ì•½": desc,
                "ì—°ë„": extract_year(item["pubDate"]),
                "ì¶œì²˜": item["originallink"]
            })

    return pd.DataFrame(rows).drop_duplicates().head(10)

# =====================
# APA
# =====================
def apa(row):
    domain = urlparse(row["ì¶œì²˜"]).netloc.replace("www.", "")
    return f"{domain}. ({row['ì—°ë„']}). {row['ì œëª©']}. {row['ì¶œì²˜']}"

# =====================
# UI
# =====================
st.title("ğŸ“š RefNote AI")
st.caption("ì¶œì²˜ ê¸°ë°˜ ë¦¬ì„œì¹˜ ì–´ì‹œìŠ¤í„´íŠ¸")

topic = st.text_input("ì–´ë–¤ ì£¼ì œë¡œ ìë£Œë¥¼ ì¤€ë¹„í•˜ë‚˜ìš”?")
task_type = st.selectbox("ê³¼ì œ ìœ í˜•", ["ë°œí‘œ", "ë¦¬í¬íŠ¸", "ê¸°íšì„œ", "ë…¼ë¬¸"])

if st.button("ë¦¬ì„œì¹˜ ì‹œì‘") and topic:
    with st.spinner("ë¦¬ì„œì¹˜ ì§„í–‰ ì¤‘..."):
        parsed = generate_questions_and_keywords(topic, task_type)
        news_df = search_naver_news(parsed["keywords"])

        st.session_state.result = {
            "questions": parsed["questions"],
            "keywords": parsed["keywords"],
            "trend": summarize_trends(parsed["keywords"]),
            "news": news_df
        }

# =====================
# Output
# =====================
if "result" in st.session_state:
    r = st.session_state.result

    st.subheader("ğŸ” ë¦¬ì„œì¹˜ ì§ˆë¬¸ (3ê°œ)")
    for q in r["questions"]:
        st.write("â€¢", q)

    st.subheader("ğŸ”‘ ê²€ìƒ‰ í‚¤ì›Œë“œ")
    st.write(", ".join(r["keywords"]))

    st.subheader("ğŸ§  ìµœì‹  ì—°êµ¬ ë™í–¥")
    st.write(r["trend"])

    st.subheader("ğŸ“Š ê·¼ê±° ìë£Œ")

    tab1, tab2 = st.tabs(["ğŸ“° ë‰´ìŠ¤", "ğŸ“„ ë…¼ë¬¸ (ì¤€ë¹„ ì¤‘)"])

    with tab1:
        st.dataframe(r["news"][["ì œëª©", "ì—°ë„", "ì¶œì²˜"]], use_container_width=True)

        st.subheader("ğŸ“ ì°¸ê³ ë¬¸í—Œ (APA í˜•ì‹, TOP 10)")
        for i, row in enumerate(r["news"].iterrows(), 1):
            st.write(f"{i}. {apa(row[1])}")

    with tab2:
        st.info("DBpia API ì—°ë™ ì˜ˆì • (ë…¼ë¬¸ ë°ì´í„°)")
