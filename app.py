import streamlit as st
import requests
import pandas as pd
import html
from datetime import datetime
from openai import OpenAI
import re

# -----------------------------
# ê¸°ë³¸ ì„¤ì •
# -----------------------------
st.set_page_config(page_title="RefNote AI", layout="wide")
st.title("ğŸ“š RefNote AI")
st.caption("ì¶œì²˜ ê¸°ë°˜ ë¦¬ì„œì¹˜ ì–´ì‹œìŠ¤í„´íŠ¸")

# -----------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# -----------------------------
if "history" not in st.session_state:
    st.session_state.history = {}

if "current_result" not in st.session_state:
    st.session_state.current_result = None

if "news_sort" not in st.session_state:
    st.session_state.news_sort = "ê´€ë ¨ë„ìˆœ"

if "paper_sort" not in st.session_state:
    st.session_state.paper_sort = "ê´€ë ¨ë„ìˆœ"

# -----------------------------
# ì‚¬ì´ë“œë°” - API Keys
# -----------------------------
st.sidebar.header("ğŸ”‘ API ì„¤ì •")

openai_key = st.sidebar.text_input("OpenAI API Key", type="password")
naver_client_id = st.sidebar.text_input("Naver Client ID", type="password")
naver_client_secret = st.sidebar.text_input("Naver Client Secret", type="password")

if openai_key:
    client = OpenAI(api_key=openai_key)
else:
    client = None

st.sidebar.markdown("---")
st.sidebar.header("ğŸ“‚ ë¦¬ì„œì¹˜ ê¸°ë¡")

if st.session_state.history:
    for label in st.session_state.history:
        if st.sidebar.button(label):
            st.session_state.current_result = st.session_state.history[label]
else:
    st.sidebar.write("ì•„ì§ ì €ì¥ëœ ë¦¬ì„œì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

# -----------------------------
# ì…ë ¥ ì˜ì—­
# -----------------------------
topic = st.text_input("ì–´ë–¤ ì£¼ì œë¡œ ìë£Œë¥¼ ì¤€ë¹„í•˜ë‚˜ìš”?")
task_type = st.selectbox("ê³¼ì œ ìœ í˜•", ["ë…¼ë¬¸", "ë°œí‘œ"])

# -----------------------------
# ìœ í‹¸ í•¨ìˆ˜
# -----------------------------
def clean_text(text):
    text = re.sub(r"<.*?>", "", text)
    text = html.unescape(text)
    return text.strip()

def parse_date(pub_date):
    try:
        dt = datetime.strptime(pub_date, "%a, %d %b %Y %H:%M:%S %z")
        return dt.strftime("%Y-%m-%d")
    except:
        return pub_date

# -----------------------------
# ë¦¬ì„œì¹˜ ì§ˆë¬¸ ìƒì„±
# -----------------------------
def generate_questions(topic, task_type):
    prompt = f"""
ì£¼ì œ: {topic}
ê³¼ì œ ìœ í˜•: {task_type}

ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ë¦¬ì„œì¹˜ ì§ˆë¬¸ 3ê°œë¥¼ ì¶œë ¥í•˜ì„¸ìš” (í•œ ì¤„ì”©)
"""
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    lines = res.choices[0].message.content.split("\n")
    return [l.strip("â€¢- ").strip() for l in lines if l.strip()]

# -----------------------------
# í‚¤ì›Œë“œ & ìµœì‹  ì—°êµ¬ ë™í–¥
# -----------------------------
def generate_keywords_trend(topic):
    prompt = f"""
ì£¼ì œ: {topic}

1. ê²€ìƒ‰ìš© í•µì‹¬ í‚¤ì›Œë“œ 5ê°œë¥¼ ì‰¼í‘œë¡œ ì¶œë ¥
2. ìµœì‹  ì—°êµ¬ ë™í–¥ì„ 3~5ë¬¸ì¥ ìš”ì•½

í˜•ì‹:
í‚¤ì›Œë“œ: a, b, c, d, e
ë™í–¥: ~
"""
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    text = res.choices[0].message.content
    parts = text.split("ë™í–¥:")
    keys_part = parts[0].split("í‚¤ì›Œë“œ:")[-1].strip()
    keywords = [k.strip() for k in keys_part.split(",")]
    trend = parts[1].strip() if len(parts) > 1 else ""
    return keywords, trend

# -----------------------------
# ë„¤ì´ë²„ ë‰´ìŠ¤ API ê²€ìƒ‰
# -----------------------------
def search_naver_news(keywords):
    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": naver_client_id,
        "X-Naver-Client-Secret": naver_client_secret
    }
    all_items = []

    for kw in keywords:
        params = {
            "query": kw,
            "display": 30,
            "sort": "date"
        }
        try:
            res = requests.get(url, headers=headers, params=params, timeout=10)
            res.raise_for_status()
        except:
            continue

        items = res.json().get("items", [])
        for item in items:
            title = clean_text(item["title"])
            desc = clean_text(item["description"])
            pubdate = parse_date(item["pubDate"])
            link = item["originallink"]

            all_items.append({
                "ì œëª©": title,
                "ìš”ì•½": desc,
                "ì¶œì²˜": link,
                "ì‘ì„±ì¼": pubdate
            })

    df = pd.DataFrame(all_items).drop_duplicates()
    return df

# -----------------------------
# ê´€ë ¨ë„ ê³„ì‚° (í‚¤ì›Œë“œ ì¶œí˜„ ë¹ˆë„)
# -----------------------------
def calculate_relevance(df, keywords):
    df["ê´€ë ¨ë„"] = df["ì œëª©"].apply(lambda t: sum(t.count(k) for k in keywords))
    return df

# -----------------------------
# APA ì°¸ê³ ë¬¸í—Œ ìƒì„±
# -----------------------------
def make_apa_list(df):
    refs = []
    for _, r in df.head(10).iterrows():
        domain = r["ì¶œì²˜"].split("/")[2]
        refs.append(
            f"{domain}. ({r['ì‘ì„±ì¼']}). {r['ì œëª©']}. {r['ì¶œì²˜']}"
        )
    return refs

# -----------------------------
# ë¦¬ì„œì¹˜ ì‹¤í–‰
# -----------------------------
if st.button("ğŸ” ë¦¬ì„œì¹˜ ì‹œì‘") and client and naver_client_id and naver_client_secret and topic:
    with st.spinner("ë¦¬ì„œì¹˜ ì§„í–‰ ì¤‘..."):
        # ë¦¬ì„œì¹˜ ì§ˆë¬¸
        questions = generate_questions(topic, task_type)

        # í‚¤ì›Œë“œ + ìµœì‹  ì—°êµ¬ ë™í–¥
        keywords, trend = generate_keywords_trend(topic)

        # ë‰´ìŠ¤ ìˆ˜ì§‘
        news_df = search_naver_news(keywords)
        news_df = calculate_relevance(news_df, keywords)

        result = {
            "topic": topic,
            "task": task_type,
            "questions": questions,
            "keywords": keywords,
            "trend": trend,
            "news": news_df,
            "papers": pd.DataFrame()  # ì¶”í›„ ë…¼ë¬¸ ì—°ë™ ì˜ˆì •
        }
        label = f"[{task_type}] {topic}"
        st.session_state.history[label] = result
        st.session_state.current_result = result

# -----------------------------
# ê²°ê³¼ ì¶œë ¥
# -----------------------------
data = st.session_state.current_result

if data:
    st.subheader("ğŸ” ë¦¬ì„œì¹˜ ì§ˆë¬¸ (3ê°œ)")
    for q in data["questions"]:
        st.write("â€¢", q)

    st.subheader("ğŸ”‘ ê²€ìƒ‰ í‚¤ì›Œë“œ")
    st.write(", ".join(data["keywords"]))

    st.subheader("ğŸ§  ìµœì‹  ì—°êµ¬ ë™í–¥")
    st.write(data["trend"])

    tab1, tab2 = st.tabs(["ğŸ“° ë‰´ìŠ¤", "ğŸ“„ ë…¼ë¬¸"])

    # ---------------- ë‰´ìŠ¤ íƒ­ ----------------
    with tab1:
        st.radio(
            "ë‰´ìŠ¤ ì •ë ¬ ê¸°ì¤€",
            ["ê´€ë ¨ë„ìˆœ", "ìµœì‹ ìˆœ"],
            key="news_sort",
            horizontal=True
        )

        df = data["news"]
        if not df.empty:
            if st.session_state.news_sort == "ê´€ë ¨ë„ìˆœ":
                sorted_news = df.sort_values("ê´€ë ¨ë„", ascending=False)
            else:
                sorted_news = df.sort_values("ì‘ì„±ì¼", ascending=False)

            st.dataframe(
                sorted_news.drop(columns=["ê´€ë ¨ë„"]),
                use_container_width=True
            )

            st.subheader("ğŸ“ ì°¸ê³ ë¬¸í—Œ (APA í˜•ì‹, TOP 10)")
            for ref in make_apa_list(sorted_news):
                st.write(ref)
        else:
            st.info("ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ---------------- ë…¼ë¬¸ íƒ­ ----------------
    with tab2:
        st.radio(
            "ë…¼ë¬¸ ì •ë ¬ ê¸°ì¤€",
            ["ê´€ë ¨ë„ìˆœ", "ìµœì‹ ìˆœ"],
            key="paper_sort",
            horizontal=True
        )
        st.info("ğŸ“„ ë…¼ë¬¸ API ì—°ë™ ì˜ˆì •ì…ë‹ˆë‹¤.")
