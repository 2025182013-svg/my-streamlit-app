import streamlit as st
import requests
import pandas as pd
from openai import OpenAI
from urllib.parse import urlparse

# =====================
# Page Config
# =====================
st.set_page_config(page_title="RefNote AI", layout="wide")

# =====================
# Sidebar - API Keys
# =====================
st.sidebar.title("ğŸ” API Keys")
openai_api_key = st.sidebar.text_input("OpenAI API Key", type="password")
naver_client_id = st.sidebar.text_input("Naver Client ID", type="password")
naver_client_secret = st.sidebar.text_input("Naver Client Secret", type="password")

if not (openai_api_key and naver_client_id and naver_client_secret):
    st.sidebar.warning("API Key ì…ë ¥ í•„ìš”")
    st.stop()

client = OpenAI(api_key=openai_api_key)

# =====================
# Session State
# =====================
if "history" not in st.session_state:
    st.session_state.history = {}

if "current" not in st.session_state:
    st.session_state.current = None

# =====================
# OpenAI Functions
# =====================
def generate_questions_and_keywords(topic, task_type):
    prompt = f"""
ì£¼ì œ: {topic}
ê³¼ì œ ìœ í˜•: {task_type}

ì•„ë˜ í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€ì¼œ.

[ë¦¬ì„œì¹˜ ì§ˆë¬¸]
1. ì§ˆë¬¸ 1
2. ì§ˆë¬¸ 2
3. ì§ˆë¬¸ 3

[ê²€ìƒ‰ í‚¤ì›Œë“œ] (ì¤‘ìš”ë„ ìˆœ 5ê°œ)
- í‚¤ì›Œë“œ1
- í‚¤ì›Œë“œ2
- í‚¤ì›Œë“œ3
- í‚¤ì›Œë“œ4
- í‚¤ì›Œë“œ5
"""
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        timeout=20
    )

    text = res.choices[0].message.content
    questions, keywords, section = [], [], None

    for line in text.split("\n"):
        line = line.strip()
        if "[ë¦¬ì„œì¹˜ ì§ˆë¬¸]" in line:
            section = "q"
        elif "[ê²€ìƒ‰ í‚¤ì›Œë“œ]" in line:
            section = "k"
        elif section == "q" and line[:2].isdigit():
            questions.append(line.split(".", 1)[1].strip())
        elif section == "k" and line.startswith("-"):
            keywords.append(line[1:].strip())

    return questions, keywords


def summarize_latest_trends(keywords):
    prompt = f"""
ë‹¤ìŒ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì‹  ì—°êµ¬ ë™í–¥ì„ 200ì ì´ë‚´ë¡œ ìš”ì•½í•´ì¤˜.
í‚¤ì›Œë“œ: {", ".join(keywords)}
"""
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
        timeout=15
    )
    return res.choices[0].message.content


# =====================
# Naver News API
# =====================
def search_naver_news(query, display=3):
    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": naver_client_id,
        "X-Naver-Client-Secret": naver_client_secret
    }
    params = {"query": query, "display": display, "sort": "date"}
    res = requests.get(url, headers=headers, params=params, timeout=10)
    if res.status_code == 200:
        return res.json().get("items", [])
    return []

# =====================
# APA Citation Generator
# =====================
def apa_citation(row):
    year = row["ì—°ë„"]
    title = row["ì œëª©"]
    url = row["ì¶œì²˜"]
    source = urlparse(url).netloc.replace("www.", "")

    return f"{source}. ({year}). {title}. {url}"

# =====================
# Sidebar - History
# =====================
st.sidebar.title("ğŸ“‚ ì €ì¥ëœ ë¦¬ì„œì¹˜")

for task_type, topics in st.session_state.history.items():
    with st.sidebar.expander(task_type):
        for topic in topics:
            if st.button(topic, key=f"{task_type}-{topic}"):
                st.session_state.current = topics[topic]

# =====================
# Main UI
# =====================
st.title("ğŸ“š RefNote AI")
st.caption("ì¶œì²˜ ê¸°ë°˜ ë¦¬ì„œì¹˜ ì–´ì‹œìŠ¤í„´íŠ¸")

topic = st.text_input("ì–´ë–¤ ì£¼ì œë¡œ ìë£Œë¥¼ ì¤€ë¹„í•˜ë‚˜ìš”?")
task_type = st.selectbox("ê³¼ì œ ìœ í˜•", ["ë°œí‘œ", "ë¦¬í¬íŠ¸", "ê¸°íšì„œ", "ë…¼ë¬¸"])

# =====================
# Research Start
# =====================
if st.button("ë¦¬ì„œì¹˜ ì‹œì‘") and topic:
    with st.spinner("ë¦¬ì„œì¹˜ ì§„í–‰ ì¤‘..."):
        questions, keywords = generate_questions_and_keywords(topic, task_type)
        trend = summarize_latest_trends(keywords)

        rows = []
        for k in keywords:
            for item in search_naver_news(k):
                rows.append({
                    "ì œëª©": item["title"],
                    "ìš”ì•½": item["description"],
                    "ì¶œì²˜": item["originallink"],
                    "ì—°ë„": item["pubDate"][:4],
                    "ê´€ë ¨ë„": keywords.index(k)
                })

        df = pd.DataFrame(rows).sort_values("ê´€ë ¨ë„").head(10)

        result = {
            "topic": topic,
            "task_type": task_type,
            "questions": questions,
            "keywords": keywords,
            "trend": trend,
            "df": df
        }

        st.session_state.current = result
        st.session_state.history.setdefault(task_type, {})[topic] = result

# =====================
# Output
# =====================
if st.session_state.current:
    data = st.session_state.current

    st.subheader("ğŸ” ë¦¬ì„œì¹˜ ì§ˆë¬¸ (3ê°œ)")
    for q in data["questions"]:
        st.write("-", q)

    st.subheader("ğŸ”‘ ì‚¬ìš©ëœ ê²€ìƒ‰ í‚¤ì›Œë“œ (ì¤‘ìš”ë„ ìˆœ)")
    for i, k in enumerate(data["keywords"], 1):
        st.write(f"{i}. {k}")

    st.subheader("ğŸ§  ìµœì‹  ì—°êµ¬ ë™í–¥ ìš”ì•½")
    st.write(data["trend"])

    st.subheader("ğŸ“Š ê·¼ê±° ìë£Œ í…Œì´ë¸” (ì£¼ìš” ê´€ë ¨ë„ ìˆœ)")
    st.dataframe(data["df"][["ì œëª©", "ì—°ë„", "ì¶œì²˜"]], use_container_width=True)

    # =====================
    # APA Citations
    # =====================
    st.subheader("ğŸ“ ì°¸ê³ ë¬¸í—Œ (APA í˜•ì‹, TOP 10)")

    for idx, row in data["df"].iterrows():
        citation = apa_citation(row)
        st.code(citation, language="text")
        st.button("ğŸ“‹ ë³µì‚¬", key=f"copy-{idx}", on_click=lambda x=citation: st.session_state.update({"_clip": x}))
        st.divider()
